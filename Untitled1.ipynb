{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellen/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(filepath):\n",
    "    file = open(filepath, 'r')\n",
    "\n",
    "    return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "senhora = open_file('books/senhora.txt')\n",
    "diva = open_file('books/diva.txt')\n",
    "gaucho = open_file('books/gaucho.txt')\n",
    "guarani = open_file('books/guarani.txt')\n",
    "iracema = open_file('books/iracema.txt')\n",
    "luciola = open_file('books/luciola.txt')\n",
    "viuvinha = open_file('books/viuvinha.txt')\n",
    "ubirajara = open_file('books/ubirajara.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista com os textos crus\n",
    "texts = [senhora, diva, gaucho, guarani, iracema, luciola, viuvinha, ubirajara]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['u', 'u', 'r', 'i', 'i', 'u', 'u', 'i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Há anos raiou no céu fluminense uma nova estre...</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emília tinha quatorze anos quando a vi pela pr...</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Como são melancólicas e solenes, ao pino do so...</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>De um dos cabeços da Serra dos Órgãos desliza ...</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Verdes mares bravios de minha terra natal, ond...</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A senhora estranhou, na última vez que estivem...</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Se passasse há dez anos pela Praia da Glória, ...</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n\\nPela marjem do grande rio caminha Jaguarê,...</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  Há anos raiou no céu fluminense uma nova estre...     u\n",
       "1  Emília tinha quatorze anos quando a vi pela pr...     u\n",
       "2  Como são melancólicas e solenes, ao pino do so...     r\n",
       "3  De um dos cabeços da Serra dos Órgãos desliza ...     i\n",
       "4  Verdes mares bravios de minha terra natal, ond...     i\n",
       "5  A senhora estranhou, na última vez que estivem...     u\n",
       "6  Se passasse há dez anos pela Praia da Glória, ...     u\n",
       "7  \\n\\nPela marjem do grande rio caminha Jaguarê,...     i"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF = pd.DataFrame()\n",
    "trainDF['text'] = texts\n",
    "trainDF['label'] = labels\n",
    "trainDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "tf_idf_vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2), norm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = count_vectorizer.fit_transform(trainDF['text'])\n",
    "X2 = tf_idf_vectorizer.fit_transform(trainDF['text'])\n",
    "X3 = vectorizer.fit_transform(trainDF['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [2, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.00247954, ..., 0.        , 0.        ,\n",
       "        0.00247954],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.01449272, 0.00724636, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 2.5040774 , ..., 0.        , 0.        ,\n",
       "        2.5040774 ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [5.00815479, 2.5040774 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação com Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    MultinomialNB(),\n",
    "    GaussianNB(),\n",
    "    MLPClassifier(alpha=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf_idf_vectorizer.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tf_idf_vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(clf, X_train, X_test):\n",
    "    c = clf.fit(X_train, train_y)\n",
    "    \n",
    "    return c.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellen/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "svm_linear = classification(classifiers[0], X_train, X_test)\n",
    "svm = classification(classifiers[1], X_train, X_test)\n",
    "svm_sgdc = classification(classifiers[2], X_train, X_test)\n",
    "decision_tree = classification(classifiers[3], X_train, X_test)\n",
    "multi_naive = classification(classifiers[4], X_train, X_test)\n",
    "gauss_naive = classification(classifiers[5], X_train.toarray(), X_test.toarray())\n",
    "neural_net = classification(classifiers[6], X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM\n",
      "['u' 'u'] 0.0\n",
      "RBF SVM\n",
      "['u' 'u'] 0.0\n",
      "SGDC SVM\n",
      "['u' 'u'] 0.0\n",
      "Decision Tree\n",
      "['u' 'u'] 0.0\n",
      "Multinominal Naive\n",
      "['u' 'u'] 0.0\n",
      "Gaussian Naive Bayes\n",
      "['u' 'u'] 0.0\n",
      "Neural Net\n",
      "['u' 'u'] 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear SVM\")\n",
    "print(svm_linear, np.mean(svm_linear == test_y))\n",
    "print(\"RBF SVM\")\n",
    "print(svm, np.mean(svm == test_y))\n",
    "print(\"SGDC SVM\")\n",
    "print(svm_sgdc, np.mean(svm_sgdc == test_y))\n",
    "print(\"Decision Tree\")\n",
    "print(decision_tree, np.mean(decision_tree == test_y))\n",
    "print(\"Multinominal Naive\")\n",
    "print(multi_naive, np.mean(multi_naive == test_y))\n",
    "print(\"Gaussian Naive Bayes\")\n",
    "print(gauss_naive, np.mean(gauss_naive == test_y))\n",
    "print(\"Neural Net\")\n",
    "print(neural_net, np.mean(neural_net == test_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação com NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(raw):\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    \n",
    "    tokens = nltk.word_tokenize(raw.lower())\n",
    "    filtered = [t for t in tokens if t not in stopwords and t.isalpha() and len(t) > 1]\n",
    "    text = nltk.Text(tokens)\n",
    "    \n",
    "    return tokens, filtered, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sra_tokens, sra_filtered, sra_text = pre_process(senhora)\n",
    "diva_tokens, diva_filtered, diva_text = pre_process(diva)\n",
    "gau_tokens, gau_filtered, gau_text = pre_process(gaucho)\n",
    "gua_tokens, gua_filtered, gua_text = pre_process(guarani)\n",
    "ira_tokens, ira_filtered, ira_text = pre_process(iracema)\n",
    "luci_tokens, luci_filtered, luci_text = pre_process(luciola)\n",
    "viu_tokens, viu_filtered, viu_text = pre_process(viuvinha)\n",
    "ubi_tokens, ubi_filtered, ubi_text = pre_process(ubirajara)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [sra_filtered, diva_filtered, gau_filtered, gua_filtered, ira_filtered, luci_filtered, viu_filtered, ubi_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF(document):\n",
    "    word_tfidf = []\n",
    "    for word in set(collection):\n",
    "        word_tfidf.append(collection.tf_idf(word,document))\n",
    "    return word_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = nltk.text.TextCollection(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "\n",
    "corpusdir = 'books/'\n",
    "corpus = PlaintextCorpusReader(corpusdir, '.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tokens = list(zip(tokens, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "filtered_words = [w.lower() for w in corpus.words() if w not in stopwords and w.isalpha() and len(w) > 1]\n",
    "\n",
    "all_words = nltk.FreqDist(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = list(all_words)[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(corpus.words(fileid)), category)\n",
    "             for category in labels\n",
    "             for fileid in corpus.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[50:], featuresets[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "naivebayes = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(naivebayes, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisiontree = nltk.DecisionTreeClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(decisiontree, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação com NLTK e Scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy percent: 38.0\n",
      "Most Informative Features\n",
      "      contains(reparava) = True                i : u      =      1.8 : 1.0\n",
      "   contains(surpreendeu) = True                i : u      =      1.8 : 1.0\n",
      "    contains(despertava) = True                i : u      =      1.8 : 1.0\n",
      "      contains(saltaram) = True                i : u      =      1.8 : 1.0\n",
      " contains(especialidade) = True                i : u      =      1.8 : 1.0\n",
      "         contains(dupla) = True                i : u      =      1.8 : 1.0\n",
      "contains(particularidades) = True                i : u      =      1.8 : 1.0\n",
      "    contains(galanteria) = True                i : u      =      1.8 : 1.0\n",
      "        contains(orelha) = True                i : u      =      1.8 : 1.0\n",
      "         contains(falem) = True                i : u      =      1.8 : 1.0\n",
      "       contains(reparei) = True                i : u      =      1.8 : 1.0\n",
      "     contains(convenceu) = True                i : u      =      1.8 : 1.0\n",
      "     contains(consumida) = True                i : u      =      1.8 : 1.0\n",
      "        contains(acudia) = True                i : u      =      1.8 : 1.0\n",
      "     contains(conhecera) = True                i : u      =      1.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "original_naive = nltk.classify.accuracy(classifier, test_set)\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (original_naive)*100)\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB_classifier accuracy percent: 44.0\n"
     ]
    }
   ],
   "source": [
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(train_set)\n",
    "MNB_accuracy = nltk.classify.accuracy(MNB_classifier, test_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (MNB_accuracy)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB_classifier accuracy percent: 38.0\n"
     ]
    }
   ],
   "source": [
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(train_set)\n",
    "BernoulliNB_accuracy = nltk.classify.accuracy(BernoulliNB_classifier, test_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (BernoulliNB_accuracy)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_classifier accuracy percent: 32.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ellen/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(train_set)\n",
    "SGDClassifier_accuracy = nltk.classify.accuracy(SGDClassifier_classifier, test_set)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (SGDClassifier_accuracy)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC_classifier accuracy percent: 32.0\n"
     ]
    }
   ],
   "source": [
    "SVC_classifier = SklearnClassifier(SVC())\n",
    "SVC_classifier.train(train_set)\n",
    "SVC_accuracy = nltk.classify.accuracy(SVC_classifier, test_set)\n",
    "print(\"SVC_classifier accuracy percent:\", (SVC_accuracy)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_classifier accuracy percent: 44.0\n"
     ]
    }
   ],
   "source": [
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(train_set)\n",
    "LinearSVC_accuracy = nltk.classify.accuracy(LinearSVC_classifier, test_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (LinearSVC_accuracy)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"NaiveBayes\": original_naive,\n",
    "    \"MNB\": MNB_accuracy,\n",
    "    \"BernoulliNB\": BernoulliNB_accuracy,\n",
    "    \"SGDClassifier\": SGDClassifier_accuracy,\n",
    "    \"SVC\": SVC_accuracy,\n",
    "    \"LinearSVC\": LinearSVC_accuracy\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd4bba7fe80>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(d).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another aproach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.DataFrame(documents, columns=[\"document\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(DF['document'], DF['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "Teste = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [48, 6]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-3e2b9cea21d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTeste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mt_svm_sgdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTeste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt_decision_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTeste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt_multi_naive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTeste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt_gauss_naive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTeste\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-d9a9dd94c1dd>\u001b[0m in \u001b[0;36mclassification\u001b[0;34m(clf, X_train, X_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [48, 6]"
     ]
    }
   ],
   "source": [
    "t_svm_linear = classification(classifiers[0], X, Teste)\n",
    "t_svm = classification(classifiers[1], X, Teste)\n",
    "t_svm_sgdc = classification(classifiers[2], X, Teste)\n",
    "t_decision_tree = classification(classifiers[3], X, Teste)\n",
    "t_multi_naive = classification(classifiers[4], X, Teste)\n",
    "t_gauss_naive = classification(classifiers[5], X.toarray(), Teste.toarray())\n",
    "t_neural_net = classification(classifiers[6], X, Teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM\n",
      "['u' 'u'] 0.0\n",
      "RBF SVM\n",
      "['u' 'u'] 0.0\n",
      "SGDC SVM\n",
      "['u' 'u'] 0.0\n",
      "Decision Tree\n",
      "['u' 'u'] 0.0\n",
      "Multinominal Naive\n",
      "['u' 'u'] 0.0\n",
      "Gaussian Naive Bayes\n",
      "['u' 'u'] 0.0\n",
      "Neural Net\n",
      "['u' 'u'] 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear SVM\")\n",
    "print(svm_linear, np.mean(svm_linear == test_y))\n",
    "print(\"RBF SVM\")\n",
    "print(svm, np.mean(svm == test_y))\n",
    "print(\"SGDC SVM\")\n",
    "print(svm_sgdc, np.mean(svm_sgdc == test_y))\n",
    "print(\"Decision Tree\")\n",
    "print(decision_tree, np.mean(decision_tree == test_y))\n",
    "print(\"Multinominal Naive\")\n",
    "print(multi_naive, np.mean(multi_naive == test_y))\n",
    "print(\"Gaussian Naive Bayes\")\n",
    "print(gauss_naive, np.mean(gauss_naive == test_y))\n",
    "print(\"Neural Net\")\n",
    "print(neural_net, np.mean(neural_net == test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
