{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from Convert_NRC.ipynb\n",
      "Importing Jupyter notebook from /home/ellen/Documentos/TextMining/header/EmotionAnalysis.ipynb\n"
     ]
    }
   ],
   "source": [
    "import nbimporter\n",
    "import matplotlib.pyplot as plt\n",
    "import Convert_NRC as nrc\n",
    "from header import EmotionAnalysis as ea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'File exists'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrc.create_emolex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(filepath):\n",
    "    raw = ea.open_file(filepath)\n",
    "\n",
    "    tokens, filtered, text, dist = ea.pre_process(raw)\n",
    "\n",
    "    ea.info(tokens, filtered)\n",
    "\n",
    "    freq = ea.most_frequent(filtered, dist)\n",
    "    print(\"20 palavras mais frequentes:\")\n",
    "    print(freq)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Palavra mais frequente: {dist.max()} - {dist[dist.max()]} vezes\")\n",
    "    print(\"\\n\")\n",
    "    print(\"Colocações significantes: \\n\")\n",
    "    print(text.collocations())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    wordList, emotionList = ea.emolex()\n",
    "    emoList = ea.newList(emotionList, filtered)\n",
    "\n",
    "    emotionCounts = ea.generate_count(wordList, filtered)\n",
    "    print(emotionCounts.most_common())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    wordCounts = ea.generate_count(emoList, filtered)\n",
    "    print(wordCounts.most_common(30))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    for w in wordCounts.most_common(30):\n",
    "        print(w[0])\n",
    "        print(wordList[w[0]])\n",
    "        print('------------------------------------')\n",
    "    \n",
    "    return dist, emotionCounts, wordCounts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Senhora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantidade de palavras: 88243\n",
      "quantidade de palavras após o filtro: 38415\n",
      "quantidade de palavras únicas: 12230\n",
      "quantidade de palavras únicas após o filtro: 10304\n",
      "diversidade léxica: 0.26822855655342964\n",
      "20 palavras mais frequentes:\n",
      "[('aurélia', 623), ('seixas', 457), ('moça', 270), ('marido', 216), ('ainda', 168), ('mulher', 167), ('casa', 144), ('havia', 137), ('fernando', 131), ('amor', 121), ('disse', 116), ('lemos', 111), ('senhor', 111), ('tempo', 110), ('alma', 110), ('casamento', 109), ('noite', 109), ('senhora', 102), ('onde', 102), ('pois', 100)]\n",
      "\n",
      "\n",
      "Palavra mais frequente: aurélia - 623 vezes\n",
      "\n",
      "\n",
      "Colocações significantes: \n",
      "\n",
      "que lhe; estas palavras; pedro camargo; dia seguinte; sua alma;\n",
      "torquato ribeiro; câmara nupcial; santa teresa; dr. torquato; por\n",
      "isso; muitas vezes; primeira vez; cem contos; ainda mais; eduardo\n",
      "abreu; que não; que ela; nesse momento; nos lábios; não lhe\n",
      "None\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-01b70e6d1d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msra_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msra_emotionCounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msra_wordCounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'books/senhora.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-d807984956e5>\u001b[0m in \u001b[0;36manalysis\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mwordList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotionList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memolex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0memoList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotionList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0memotionCounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/TextMining/header/EmotionAnalysis.ipynb\u001b[0m in \u001b[0;36mnewList\u001b[0;34m(emotionList, filtered_tokens)\u001b[0m\n\u001b[1;32m      3\u001b[0m   {\n\u001b[1;32m      4\u001b[0m    \u001b[0;34m\"cell_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"markdown\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m    \u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m    \"source\": [\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"## Imports e downloads\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sra_freq, sra_emotionCounts, sra_wordCounts = analysis('books/senhora.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diva_freq, diva_emotionCounts, diva_wordCounts = analysis('books/diva.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Gaucho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauc_freq, gauc_emotionCounts, gauc_wordCounts = analysis('books/gaucho.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Guarani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guar_freq, guar_emotionCounts, guar_wordCounts = analysis('books/guarani.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iracema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ira_freq, ira_emotionCounts, ira_wordCounts = analysis('books/iracema.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ubirajara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubi_freq, ubi_emotionCounts, ubi_wordCounts = analysis('books/ubirajara.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luciola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "luci_freq, luci_emotionCounts, luci_wordCounts = analysis('books/luciola.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Viuvinha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viu_freq, viu_emotionCounts, viu_wordCounts = analysis('books/viuvinha.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sra_freq.plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diva_freq.plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauc_freq.plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guar_freq.plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ira_freq.plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubi_freq.plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "luci_freq.plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viu_freq.plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sra_emotionCounts).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(diva_emotionCounts).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(gauc_emotionCounts).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(guar_emotionCounts).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(ira_emotionCounts).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(ubi_emotionCounts).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(luci_emotionCounts).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(viu_emotionCounts).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
